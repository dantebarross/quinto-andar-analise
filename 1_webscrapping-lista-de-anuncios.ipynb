{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b0a04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import csv\n",
    "\n",
    "# Função utilizada para realizar o merge de arquivos CSV, contidos em um PATH, para um dado PATH\n",
    "def merge_csv_path(path_in, path_out):\n",
    "    all_files = glob.glob(path_in + \"*.csv\")\n",
    "    li = []\n",
    "\n",
    "    for filename in all_files:\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        li.append(df)\n",
    "\n",
    "    frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "    frame.to_csv(path_out + 'merge_csv_path.csv')\n",
    "    \n",
    "# Indique em path_in a pasta contendo os arquivos CSV a serem juntados, e em path_out a pasta a ser gerada o arquivo concatenado\n",
    "path_in = 'C:/Users/PC/Desktop/quinto-andar-analise/lista_urls/'\n",
    "path_out = 'C:/Users/PC/Desktop/quinto-andar-analise/'\n",
    "# merge_csv_path(path_in, path_out) # Descomente para executar a função.\n",
    "\n",
    "\n",
    "\n",
    "# Função utilizada para coletar os diversos anúncios do portal QuintoAndar. \n",
    "def coleta_de_anuncios(url, loop_de_coleta, path_out):\n",
    "    option = Options()\n",
    "    option.headless = True # Se for True, interface gráfica não será aberta\n",
    "    driver = webdriver.Firefox(executable_path='geckodriver\\geckodriver.exe', options=option)\n",
    "\n",
    "    # Abre a URL\n",
    "    driver.get(url)\n",
    "\n",
    "    # Faz o scroll down para mostrar todos os resultados.\n",
    "    time.sleep(15)\n",
    "    div_scroll = driver.find_element_by_class_name('sc-5ca2ou-0.TybLn')\n",
    "    loop = 61\n",
    "    urls_coletadas = 0\n",
    "\n",
    "    for i in range(60):\n",
    "        div_scroll.send_keys(Keys.END)\n",
    "        time.sleep(1)\n",
    "\n",
    "    for main in range(loop_de_coleta):\n",
    "        print(\"loop: \" + str(loop) + \" de \" + str(rangers))\n",
    "        loop += 1\n",
    "        for i in range(10):\n",
    "            div_scroll.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(1)\n",
    "\n",
    "        for i in range(7):\n",
    "            div_scroll.send_keys(Keys.PAGE_UP)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Coleta todas as URLs utilizando a classe \"href\", que são links\n",
    "        elems = driver.find_elements_by_xpath(\"//a[@href]\")\n",
    "        time.sleep(5)\n",
    "        lista_urls = {'urls': []}\n",
    "\n",
    "        for elem in elems:\n",
    "            link_geral = str(elem.get_attribute(\"href\"))\n",
    "            if ('imovel/8') in link_geral: # O texto 'imovel/8' é um indício de que o link colhido é o de um anúncio de imóvel\n",
    "                #print(link_geral)\n",
    "                lista_urls['urls'].append(link_geral)\n",
    "\n",
    "        # Estruturando conteúdo em diversos arquivos CSV\n",
    "        df = pd.DataFrame(lista_urls)\n",
    "        df.to_csv(path_out + str(loop) + '_lista_urls_pandas.csv')\n",
    "        print('elementos na lista de URLs: ' + str(len(lista_urls['urls'])))\n",
    "        urls_coletadas = urls_coletadas + len(lista_urls['urls'])\n",
    "        print(urls_coletadas)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "# URL contendo os anúncios. Neste caso da cidade de São Paulo\n",
    "url = 'https://www.quintoandar.com.br/alugar/imovel/sao-paulo-sp-brasil/' \n",
    "# Número de loop de coletas. Cada loop colhe cerca de 10 URLs. (Não há como colher todas as URLs geradas, apenas algumas por vez).\n",
    "loop_de_coleta = 500\n",
    "# Path que será criado os diversos arquivos CSV contendo as listas de URLs. Utilize a função merge_csv_path para que os arquivos sejam concatenados em um único CSV.\n",
    "path_out = 'C:/Users/PC/Desktop/quinto-andar-analise/lista_urls/'\n",
    "\n",
    "#coleta_de_anuncios(url, loop_de_coleta, path_out) # Descomente para chamar a função\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0de32a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
